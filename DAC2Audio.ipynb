{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42beb825",
   "metadata": {},
   "source": [
    "### <font color='blue'> DAC to audio \n",
    "</font>\n",
    "\n",
    "This notebook reads a DAC file and uses the descript 44.1kHz pretrained DAC to decompress it to audio.   \n",
    "It is in a separate file from the transformer generative code because it takes up too much memory (which doesn't seem right).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "\n",
    "# and for creating a custom dataset and loader:\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import dac\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70895dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826db54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "# Function to find all tensors on CUDA\n",
    "def get_cuda_tensors():\n",
    "    cuda_tensors = []\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) and obj.is_cuda:\n",
    "                cuda_tensors.append((type(obj), obj.size()))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return cuda_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f12f85d",
   "metadata": {},
   "source": [
    "### <font color='blue'> Parameters \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data dir\n",
    "#experiment_name='experiment_onesnd_small' \n",
    "\n",
    "cptnum=100\n",
    "tstsnd='bees'\n",
    "experiment_name='newscratchbeescond8'\n",
    "#fname=tstsnd+'.e56.l4.h8_chkpt_'+str(cptnum).zfill(4)\n",
    "\n",
    "#must match a specific dac file name used\n",
    "minpval=0\n",
    "maxpval=0\n",
    "inference_steps=86*20\n",
    "\n",
    "fname=tstsnd+'.e504.l2.h4_chkpt_' + str(cptnum).zfill(4) + \"_steps_\"+str(inference_steps).zfill(4)+'.minpval_'+ f\"{minpval:01.2f}\" +'.maxpval_'+ f\"{maxpval:01.2f}\"\n",
    "SAVEWAV=False\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# I am having with running out of memory loading the DAC model with cuda. CPU runs pretty fast\n",
    "# for decompressing, so there ya go. \n",
    "DEVICE='cpu'\n",
    "\n",
    "# --------  derived ------ don't change these \n",
    "data_dir= 'runs' + '/' + experiment_name\n",
    "selected_file=data_dir+'/' + fname + \".dac\"\n",
    "\n",
    "print(f' fname is {fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "\n",
    "device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "torch.cuda.device_count()\n",
    "print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a7974",
   "metadata": {},
   "source": [
    "### <font color='blue'> Get the DAC model \n",
    "that will be need *after* we run the transformer in order to reconstruct the signal from codes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5330b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you do this, it can take a while. Go get coffee. After that, it uses a cached version\n",
    "dacmodel_path = dac.utils.download(model_type=\"44khz\") \n",
    "\n",
    "with torch.no_grad():\n",
    "    dacmodel = dac.DAC.load(dacmodel_path)\n",
    "\n",
    "    dacmodel.to(device); #wanna see the model? remove the semicolon\n",
    "    dacmodel.eval();  # need to be \"in eval mode\" in order to set the number of quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'd like to have the user choose files from a dropdown list, but I think I have to \n",
    "#     add nbextensions to jupyter lab, and don't have permissions to do that.\n",
    "\n",
    "\n",
    "# files = os.listdir(data_dir)\n",
    "\n",
    "# # Create a dropdown widget\n",
    "# file_dropdown = widgets.Dropdown(\n",
    "#     options=files,\n",
    "#     description='Files:',\n",
    "# )\n",
    "\n",
    "# # Display the dropdown\n",
    "# display(file_dropdown)\n",
    "\n",
    "# # Define a global variable to store the selected file\n",
    "# selected_file = None\n",
    "\n",
    "# # Function to handle the selection\n",
    "# def on_file_change(change):\n",
    "#     global selected_file_global\n",
    "#     selected_file_global = change['new']\n",
    "#     print(f'You selected: {selected_file}')\n",
    "   \n",
    "# # Attach the handler to the dropdown\n",
    "# file_dropdown.observe(on_file_change, names='value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb6338",
   "metadata": {},
   "source": [
    "### <font color='blue'> Codes-2-Audio reconstruction\n",
    "that will be need *after* we run the transformer in order to reconstruct the signal from codes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eef7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dacfile = dac.DACFile.load(selected_file)\n",
    "    # FIRST - Decompress it back to an AudioSignal\\ from codes to z (1024) to signal   \n",
    "    print(f'dacfile.codes shape is: {dacfile.codes.shape}')\n",
    "    t0=time.time()\n",
    "    asig=dacmodel.decompress(dacfile)\n",
    "    t1=time.time()\n",
    "    \n",
    "inf_time = t1-t0\n",
    "print(f'decompress time for {asig.audio_data.shape[2]/44100} seconds of sound is {inf_time}' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asig.audio_data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "asig.cpu().widget()\n",
    "asig.audio_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adata = asig.samples.view(-1).numpy()\n",
    "if SAVEWAV :  \n",
    "    sf.write(data_dir+'/' + fname + \".wav\", adata, 44100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5154341",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(adata)\n",
    "ipd.Audio(adata, rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2db1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will list every variable on cuda if you are using it. \n",
    "cuda_tensors = get_cuda_tensors()\n",
    "for tensor_type, tensor_size in cuda_tensors:\n",
    "    print(f'Type: {tensor_type}, Size: {tensor_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6a208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba798ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
